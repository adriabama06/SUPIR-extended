services:
  supir-extended:
    image: adriabama06/supir-extended # This image does not exist, is only to get this name in docker images and not an automatically generated name
    build:
      dockerfile: Dockerfile
      context: .
    network_mode: bridge
    container_name: supir-extended
    healthcheck:
      test: curl --fail http://localhost:6688 || exit 1
      interval: 60s
      retries: 5
      start_period: 20s
      timeout: 10s
    ports:
      - 6688:6688
    environment:
      - OPENAI_API_BASE=https://api.openai.com/v1 # If you use ollama also set the url using /v1
      - OPENAI_API_KEY=NOT-SET
      - OPENAI_MODEL=gpt-4o-mini
      - OPENAI_BACKEND=ollama # ollama | tabbyapi <-- This is used to unload the model to free up memory, set any other string to not unload, example: OPENAI_BACKEND=none
      - USE_OPENAI=off # on | off <-- off will indicate that llava will be used
    volumes:
      - models:/app/models
      - outputs:/app/outputs
      - ./entrypoint.sh:/app/entrypoint.sh
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all # To use specifics GPUs --> device_ids: ['0']
              capabilities: [gpu]

volumes:
  models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./models
  outputs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./outputs
